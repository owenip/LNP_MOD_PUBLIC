{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/owenip/LNP-MOD/blob/dev/YoloV8Training.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the notebook is using GPU via `nvidia-smi` command.\n",
    "In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.\n",
    "\n",
    "*This tool can also work without GPU but the processing time will be significantly longer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ##Run this cell to check if you have GPU access { display-mode: \"form\" }\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "display.clear_output()\n",
    "\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('\\nYou do not have GPU access.')\n",
    "    print('\\nDid you change your runtime ?')\n",
    "    print('\\nIf the runtime setting is correct then Google did not allocate a GPU for your session')\n",
    "    print('\\nExpect slow performance. To access GPU try reconnecting later')\n",
    "\n",
    "else:\n",
    "    print('You have GPU access')\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mount your Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ##Play the cell to connect your Google Drive to Colab { display-mode: \"form\" }\n",
    "\n",
    "# @markdown 1. Click 'Connect to Google Drive' at the pop up window\n",
    "\n",
    "# @markdown 2. Sign in your Google Account.\n",
    "\n",
    "# @markdown 3. Click 'Allow' to give this notebook access to the data on the drive\n",
    "\n",
    "# @markdown * Once this is done, your data are available in the Files tab on the top left of notebook.\n",
    "\n",
    "# Mount user's Google Drive to Google Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Force session restart\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics library\n",
    "from IPython import display\n",
    "%pip install -U ultralytics \n",
    "\n",
    "display.clear_output()\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ### Setup Dataset and Model { display-mode: \"form\" }\n",
    "# @markdown ### Provide the path to the dataset folder\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def check_file_exist(file_path):\n",
    "    if os.path.exists(file_path) == False:\n",
    "        raise Exception('File does not exist: ' + file_path)\n",
    "\n",
    "def get_supported_images_path_list(images_folder):\n",
    "    images = []\n",
    "    # Exclude '*.jpg', '*.jpeg' as this format are always used for the overview image\n",
    "    supported_images = ('*.tif', '*.tiff', '*.png', '*.bmp',\n",
    "                        '*.dng', '*.webp', '*.pfm', '*.mpo')\n",
    "    for image_type in supported_images:\n",
    "        images.extend(glob.glob(images_folder + 'training/images/' + image_type))\n",
    "        images.extend(glob.glob(images_folder + 'validation/images/' + image_type))\n",
    "\n",
    "\n",
    "    return sorted(images)\n",
    "\n",
    "path_to_dataset_folder = \"/content/drive/Shareddrives/Bleb_Counting/dataset/\"  # @param {type:\"string\"}\n",
    "path_to_dataset_config_file = \"/content/drive/Shareddrives/Bleb_Counting/dataset/data.yaml\" # @param {type:\"string\"}\n",
    "epochs = 200  # @param {type:\"integer\"}\n",
    "batch_size = 16  # @param {type:\"integer\"}\n",
    "workers = 8  # @param {type:\"integer\"}\n",
    "image_width = 4096  # @param {type:\"integer\"}\n",
    "image_height = 4224  # @param {type:\"integer\"}\n",
    "\n",
    "# @markdown ### Image Augmentation\n",
    "translate = 0.1  # @param {type:\"number\"}\n",
    "scale = 0.5  # @param {type:\"number\"}\n",
    "shear = 0.1  # @param {type:\"number\"}\n",
    "flipud = 0.0  # @param {type:\"number\"}\n",
    "fliplr = 0.5  # @param {type:\"number\"}\n",
    "mosaic = 1.0  # @param {type:\"number\"}\n",
    "\n",
    "### Resume Training\n",
    "resume_training = False # @param {type:\"boolean\"}\n",
    "path_to_model = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "check_file_exist(path_to_dataset_folder)\n",
    "if resume_training:\n",
    "    check_file_exist(path_to_model)\n",
    "dataset_folder = os.path.join(path_to_dataset_folder)\n",
    "predict_result_folder = os.path.join(path_to_dataset_folder + 'predict/')\n",
    "\n",
    "num_of_supported_images = len(get_supported_images_path_list(dataset_folder))\n",
    "if num_of_supported_images == 0:\n",
    "    raise Exception('No supported images found in the dataset folder')\n",
    "else:\n",
    "    print('Number of supported images found in the dataset folder: ' + str(num_of_supported_images))\n",
    "\n",
    "\n",
    "# @markdown #*Play the cell to ensure the dataset folder contains supported images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {path_to_dataset_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if resume_training == True:\n",
    "    model = YOLO(path_to_model)\n",
    "else:\n",
    "    model = YOLO(f'yolov8x.pt')\n",
    "\n",
    "model.train(\n",
    "    device=0,\n",
    "    epochs=epochs,\n",
    "    data=path_to_dataset_config_file,\n",
    "    project=path_to_dataset_folder,\n",
    "    imgsz=[image_height, image_width],\n",
    "    plots=True,\n",
    "    batch=batch_size,\n",
    "    save=True,\n",
    "    resume=resume_training,\n",
    "    cache='disk',\n",
    "    workers=workers,\n",
    "    translate=translate,\n",
    "    scale=scale,\n",
    "    shear=shear,\n",
    "    flipud=flipud,\n",
    "    fliplr=fliplr,\n",
    "    mosaic=mosaic\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images with Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patchify Images and annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installed requried functions and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patchify\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import Decimal, getcontext\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "getcontext().prec = 6\n",
    "\n",
    "BLEB_WITH_MRNA = 0\n",
    "ICE_CRYSTAL = 1\n",
    "OIL_CORE = 2\n",
    "OTHER_LNP = 4\n",
    "NOT_FULLY_VISIBLE_LNP = 3\n",
    "\n",
    "def create_folder_if_not_exist(folder_path):\n",
    "  if os.path.isdir(folder_path) == False:\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "\n",
    "def is_valid_annotation_after_splitting(standard_bbox):\n",
    "    is_valid = True\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    if bbox_width < 1 or bbox_height < 1:\n",
    "        is_valid = False\n",
    "    if bbox_width > 2048 or bbox_height > 2048:\n",
    "        is_valid = False\n",
    "    if x_min < 0 or x_max > 2048:\n",
    "        is_valid = False\n",
    "    if y_min < 0 or y_max > 2048:\n",
    "        is_valid = False\n",
    "\n",
    "    return is_valid\n",
    "\n",
    "\n",
    "def is_valuable_annotation(standard_bbox):\n",
    "    is_valuable = True\n",
    "    bbox_area_threshold = 10\n",
    "    bbox_width_threshold = 5\n",
    "    bbox_height_threshold = 5\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    if (bbox_width * bbox_height) < bbox_area_threshold or bbox_width < bbox_width_threshold or bbox_height < bbox_height_threshold:\n",
    "        is_valuable = False\n",
    "\n",
    "    return is_valuable\n",
    "\n",
    "\n",
    "def check_bbox(bbox, x_range=[0, 1], y_range=[0, 1]):\n",
    "    _bbox = bbox[1:]\n",
    "    _bbox = map(Decimal, _bbox)\n",
    "    x_min, y_min, x_max, y_max, bbox_width, bbox_height = _bbox\n",
    "\n",
    "    for name, value in zip(['x_min', 'x_max'], [x_min, x_max]):\n",
    "        if not x_range[0] <= value <= x_range[1] and not np.isclose(float(value), x_range[0]) and not np.isclose(float(value), x_range[1]):\n",
    "            raise ValueError(\n",
    "                f\"Expected {name} for bbox {bbox} to be in {x_range}, got {value}\")\n",
    "\n",
    "    for name, value in zip(['y_min', 'y_max'], [y_min, y_max]):\n",
    "        if not y_range[0] <= value <= y_range[1] and not np.isclose(float(value), y_range[0]) and not np.isclose(float(value), y_range[1]):\n",
    "            raise ValueError(\n",
    "                f\"Expected {name} for bbox {bbox} to be in {y_range}, got {value}\")\n",
    "\n",
    "    if x_max < x_min:\n",
    "        raise ValueError(\n",
    "            f\"xmax is less than or equal to x_min for bbox {bbox}\")\n",
    "    if y_max < y_min:\n",
    "        raise ValueError(\n",
    "            f\"ymax is less than or equal to y_min for bbox {bbox}\")\n",
    "\n",
    "\n",
    "def check_yolo_box(yolo_bbox):\n",
    "    check_bbox(yolo_bbox, x_range=[0, 1], y_range=[0, 1])\n",
    "    for name, value in zip(['bbox_width', 'bbox_height'], yolo_bbox[5:]):\n",
    "        if not 0 <= value <= 1 and not np.isclose(value, 0) and not np.isclose(value, 1):\n",
    "            raise ValueError(\n",
    "                f\"Expected {name} for bbox {yolo_bbox} to be in [0.0, 1.0], got {value}\")\n",
    "\n",
    "\n",
    "def fix_bbox(bbox, x_range=[0, 1], y_range=[0, 1]):\n",
    "    _bbox = bbox[1:]\n",
    "    _bbox = map(Decimal, _bbox)\n",
    "    x_min, y_min, x_max, y_max, bbox_width, bbox_height = _bbox\n",
    "\n",
    "    if x_min < x_range[0]:\n",
    "        print('x_min < x_range[0]', x_min, x_range[0])\n",
    "    \n",
    "    if x_max > x_range[1]:\n",
    "        print('x_max > x_range[1]', x_max, x_range[1])\n",
    "    \n",
    "    if y_min < y_range[0]:\n",
    "        print('y_min < y_range[0]', y_min, y_range[0])\n",
    "    \n",
    "    if y_max > y_range[1]:\n",
    "        print('y_max > y_range[1]', y_max, y_range[1])\n",
    "    \n",
    "    return [bbox[0], x_min.max(x_range[0]), y_min.max(y_range[0]), x_max.min(x_range[1]), y_max.min(y_range[1]), bbox_width, bbox_height]\n",
    "\n",
    "\n",
    "def fix_bboxes(bboxes, x_range=[0, 1], y_range=[0, 1]):\n",
    "  for index, bbox in enumerate(bboxes):\n",
    "    if len(bbox) == 0:\n",
    "      continue\n",
    "    bboxes[index] = fix_bbox(bbox, x_range, y_range)\n",
    "\n",
    "  return bboxes\n",
    "\n",
    "\n",
    "def update_edge_label(bbox, from_labels=[BLEB_WITH_MRNA, OTHER_LNP], to_label=NOT_FULLY_VISIBLE_LNP):\n",
    "    if bbox[0] in from_labels:\n",
    "        bbox[0] = to_label\n",
    "\n",
    "    return bbox\n",
    "\n",
    "\n",
    "def update_edge_labels(bboxes, from_labels=[BLEB_WITH_MRNA, OTHER_LNP], to_label=NOT_FULLY_VISIBLE_LNP):\n",
    "    for index, bbox in enumerate(bboxes):\n",
    "        if len(bbox) == 0:\n",
    "            continue\n",
    "        bboxes[index] = update_edge_label(bbox, from_labels, to_label)\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "def update_on_edge_LNP_labels(bboxes, from_labels=[BLEB_WITH_MRNA, OTHER_LNP], to_label=NOT_FULLY_VISIBLE_LNP):\n",
    "    return update_edge_labels(bboxes, from_labels, to_label)\n",
    "\n",
    "def check_splitted_annotation(regions):\n",
    "    for index, bbox in enumerate(regions):\n",
    "        if len(bbox) == 0:\n",
    "            break\n",
    "\n",
    "        if is_valid_annotation_after_splitting(bbox) == False:\n",
    "            print('Invalid annotation at region', index,  bbox)\n",
    "            regions[index] = []\n",
    "\n",
    "        check_bbox(bbox, x_range=[0, 2048], y_range=[0, 2048])\n",
    "\n",
    "    # Remove splitted annotation is not valuable\n",
    "    for index, bbox in enumerate(regions):\n",
    "        if len(bbox) == 0:\n",
    "            break\n",
    "\n",
    "        if is_valuable_annotation(bbox) == False:\n",
    "            print('Not valuable annotation at region', index,  bbox)\n",
    "            regions[index] = []\n",
    "\n",
    "    return regions\n",
    "\n",
    "\n",
    "def convert_yolo_bbox_to_standard_bbox(yolo_bbox, img_width=4096, img_height=4224):\n",
    "    # Convert yolo normalized coordinates to normal coordinates\n",
    "    label, norm_x_center, norm_y_center, norm_width, norm_height = yolo_bbox\n",
    "    x_center = Decimal(norm_x_center) * img_width\n",
    "    y_center = Decimal(norm_y_center) * img_height\n",
    "\n",
    "    bbox_width = Decimal(norm_width) * img_width\n",
    "    bbox_height = Decimal(norm_height) * img_height\n",
    "\n",
    "    x_min = x_center - (bbox_width/2)\n",
    "    x_max = x_center + (bbox_width/2)\n",
    "    y_min = y_center - (bbox_height/2)\n",
    "    y_max = y_center + (bbox_height/2)\n",
    "\n",
    "    return [label, x_min, y_min, x_max, y_max, bbox_width, bbox_height]\n",
    "\n",
    "\n",
    "def convert_standard_bbox_to_yolo_format(standard_bbox, img_width=2048, img_height=2048):\n",
    "    # Convert normal coordinates to yolo normalized coordinates\n",
    "    label = standard_bbox[0]\n",
    "    _standard_bbox = standard_bbox[1:]\n",
    "    _standard_bbox = map(Decimal, _standard_bbox)\n",
    "    x_min, y_min, x_max, y_max, bbox_width, bbox_height = _standard_bbox\n",
    "\n",
    "    x_center = (x_min + x_max) / Decimal(2)\n",
    "    y_center = (y_min + y_max) / Decimal(2)\n",
    "    height = y_max - y_min\n",
    "    width = x_max - x_min\n",
    "\n",
    "    norm_x_center = x_center / img_width\n",
    "    norm_y_center = y_center / img_height\n",
    "    norm_width = width / img_width\n",
    "    norm_height = height / img_height\n",
    "\n",
    "    return [label, norm_x_center, norm_y_center, norm_width, norm_height]\n",
    "\n",
    "\n",
    "def split_annotation_accross_x_axis_left_of_y_axis(standard_bbox, patch_width=2048, patch_height=2048):\n",
    "    # Convert annotation that is splitted by x axis\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    bbox_1 = [label, x_min, y_min, x_max, patch_height, bbox_width, patch_height - y_min]\n",
    "    bbox_2 = [label, x_min, 0, x_max, y_max - patch_height, bbox_width, y_max - patch_height]\n",
    "\n",
    "    region_bboxes = fix_bboxes([bbox_1, [],  bbox_2, []], [0, patch_width - 1], [0, patch_height - 1])\n",
    "\n",
    "    return check_splitted_annotation(region_bboxes)\n",
    "\n",
    "\n",
    "def split_annotation_accross_x_axis_right_of_y_axis(standard_bbox, patch_width=2048, patch_height=2048):\n",
    "    # Convert annotation that is splitted by x axis\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    bbox_1 = [label, x_min - patch_width, y_min, x_max - patch_width, patch_height, bbox_width, patch_height - y_min]\n",
    "    bbox_2 = [label, x_min - patch_width, 0, x_max - patch_width, y_max - patch_height, bbox_width, y_max - patch_height]\n",
    "\n",
    "    region_bboxes = fix_bboxes([[], bbox_1, [], bbox_2], [\n",
    "                               0, patch_width - 1], [0, patch_height - 1])\n",
    "\n",
    "    return check_splitted_annotation(region_bboxes)\n",
    "\n",
    "\n",
    "def split_annotation_accross_y_axis_above_x_axis(standard_bbox, patch_width=2048, patch_height=2048):\n",
    "    # Convert annotation that is splitted by y axis above x axis\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    bbox_1 = [label, x_min, y_min, patch_width, y_max, patch_width - x_min, bbox_height]\n",
    "    bbox_2 = [label, 0, y_min, x_max - patch_width, y_max, x_max - patch_width, bbox_height]\n",
    "\n",
    "    region_bboxes = fix_bboxes([bbox_1, bbox_2, [], []], [0, patch_width - 1], [0, patch_height - 1])\n",
    "\n",
    "    return check_splitted_annotation(region_bboxes)\n",
    "\n",
    "\n",
    "def split_annotation_accross_y_axis_below_x_axis(standard_bbox, patch_width=2048, patch_height=2048):\n",
    "    # Convert annotation that is splitted by y axis below x axis\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    bbox_1 = [label, x_min, y_min - patch_height, patch_width,\n",
    "              y_max - patch_height, patch_width - x_min, bbox_height]\n",
    "    bbox_2 = [label, 0, y_min - patch_height, x_max - patch_width, y_max - patch_height, x_max - patch_width, bbox_height]\n",
    "\n",
    "    region_bboxes = fix_bboxes([[], [], bbox_1, bbox_2], [\n",
    "                               0, patch_width - 1], [0, patch_height - 1])\n",
    "\n",
    "    return check_splitted_annotation(region_bboxes)\n",
    "\n",
    "\n",
    "def split_annotation_accross_center(standard_bbox, patch_width=2048, patch_height=2048):\n",
    "    # Convert annotation that is splitted by center\n",
    "    label, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    bbox_1 = [label, x_min, y_min, patch_width, patch_height, patch_width - x_min, patch_height - y_min]\n",
    "    bbox_2 = [label, 0, y_min, x_max - patch_width, patch_height, x_max - patch_width, patch_height - y_min]\n",
    "    bbox_3 = [label, x_min, 0, patch_width, y_max - patch_height, patch_width - x_min, y_max - patch_height]\n",
    "    bbox_4 = [label, 0, 0, x_max - patch_width, y_max - patch_height, x_max - patch_width, y_max - patch_height]\n",
    "\n",
    "    region_bboxes = fix_bboxes([bbox_1, bbox_2, bbox_3, bbox_4], [\n",
    "                               0, patch_width - 1], [0, patch_height - 1])\n",
    "\n",
    "    return check_splitted_annotation(region_bboxes)\n",
    "\n",
    "\n",
    "# Regions are divided into 4 parts: top left, top right, bottom left, bottom right\n",
    "\n",
    "def patchify_bbox(standard_bbox, patch_width=2048, patch_height=2048, update_on_edge_labels=True):\n",
    "    result = []\n",
    "    class_name, x_min, y_min, x_max, y_max, bbox_width, bbox_height = standard_bbox\n",
    "\n",
    "    if x_min < patch_width:\n",
    "        if y_min < patch_height:\n",
    "            if x_max < patch_width:\n",
    "                if y_max < patch_height:\n",
    "                    result = [[class_name, x_min, y_min, x_max, y_max, bbox_width, bbox_height], [], [], []]\n",
    "                else:\n",
    "                    result = split_annotation_accross_x_axis_left_of_y_axis(standard_bbox, patch_width, patch_height)\n",
    "            else:\n",
    "                if y_max < patch_height:\n",
    "                    result = split_annotation_accross_y_axis_above_x_axis(\n",
    "                        standard_bbox, patch_width, patch_height)\n",
    "                else:\n",
    "                    result = split_annotation_accross_center(standard_bbox, patch_width, patch_height)\n",
    "        else:\n",
    "            if x_max < patch_width:\n",
    "                result = [[], [], [class_name, x_min, y_min - patch_height, x_max, y_max - patch_height, bbox_width, bbox_height], []]\n",
    "            else:\n",
    "                result = split_annotation_accross_y_axis_below_x_axis(standard_bbox, patch_width, patch_height)\n",
    "    else:\n",
    "        if y_min < patch_height:\n",
    "            if y_max < patch_height:\n",
    "                result = [[], [class_name, x_min - patch_width, y_min, x_max - patch_width, y_max, bbox_width, bbox_height], [], []]\n",
    "            else:\n",
    "                result = split_annotation_accross_x_axis_right_of_y_axis(standard_bbox, patch_width, patch_height)\n",
    "        else:\n",
    "            result = [[], [], [], [class_name, x_min - patch_width, y_min - patch_height, x_max - patch_width, y_max - patch_height, bbox_width, bbox_height]]\n",
    "\n",
    "    if update_on_edge_labels == True:\n",
    "        result = update_on_edge_LNP_labels(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ### Pachify Paramters { display-mode: \"form\" }\n",
    "# @markdown ### Provide the path to the dataset folder\n",
    "patch_width = 2048  # @param {type:\"integer\"}\n",
    "patch_height = 2048  # @param {type:\"integer\"}\n",
    "patch_step = 2048  # @param {type:\"integer\"}\n",
    "\n",
    "dataset = ''  # @param {type:\"string\"}\n",
    "dataset_folder = os.path.join(dataset, '')\n",
    "images_folder = os.path.join(dataset_folder, 'images', '')\n",
    "labels_folder = os.path.join(dataset_folder, 'labels', '')\n",
    "\n",
    "output_folder = '' # @param {type:\"string\"}\n",
    "output_folder = os.path.join(output_folder, '')\n",
    "output_images_folder = os.path.join(output_folder, 'images', '')\n",
    "output_labels_folder = os.path.join(output_folder, 'labels', '')\n",
    "\n",
    "create_folder_if_not_exist(output_folder)\n",
    "create_folder_if_not_exist(output_images_folder)\n",
    "create_folder_if_not_exist(output_labels_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image:  Sample7_73kx_0001.tif\n"
     ]
    }
   ],
   "source": [
    "# @title ##Play the cell to generate patches { display-mode: \"form\" }\n",
    "\n",
    "import glob\n",
    "# Only process images in the images folder\n",
    "getcontext().prec = 6\n",
    "images_total_count = len(glob.glob1(images_folder, '*.png'))\n",
    "images_list = os.listdir(images_folder)\n",
    "\n",
    "for index, image in enumerate(images_list):\n",
    "    if not image.endswith('.png') and not image.endswith('.tif'):\n",
    "        continue\n",
    "\n",
    "    filename = image.split('.')[0]\n",
    "    label_file = os.path.join(labels_folder, filename + '.txt')\n",
    "    print(f\"Processing:{index + 1}/{images_total_count}: {image}\")\n",
    "\n",
    "    # Check if label file exists\n",
    "    if os.path.isfile(label_file) == False:\n",
    "        print('Label file does not exist: ', label_file)\n",
    "        continue\n",
    "\n",
    "    # Patchify image\n",
    "    img = cv2.imread(os.path.join(images_folder, image), 0)\n",
    "    img_h, img_w = img.shape\n",
    "    patches = patchify.patchify(\n",
    "        img, (patch_width, patch_height), step=patch_step)\n",
    "    counter = 0\n",
    "    for i in range(patches.shape[0]):\n",
    "        for j in range(patches.shape[1]):\n",
    "            single_patch = patches[i, j, :, :]\n",
    "            plt.imsave(os.path.join(output_images_folder,\n",
    "                       f\"{filename}_patch_{str(counter)}.png\"), single_patch, cmap='gray')\n",
    "            counter += 1\n",
    "\n",
    "    # Read label file\n",
    "    with open(label_file, 'r') as f:\n",
    "        label_lines = f.readlines()\n",
    "\n",
    "    # Split annotation\n",
    "    converted_bboxes = [[], [], [], []]\n",
    "    for line in label_lines:\n",
    "        line = line.split(' ')\n",
    "        standard_bbox = convert_yolo_bbox_to_standard_bbox(\n",
    "            line, img_w, img_h)\n",
    "\n",
    "        # Convert to patch coordinates\n",
    "        patchify_bboxes = patchify_bbox(\n",
    "            standard_bbox, patch_width, patch_height)\n",
    "        for index, bboxes in enumerate(converted_bboxes):\n",
    "            converted_bboxes[index].append(patchify_bboxes[index])\n",
    "\n",
    "    # Write label file in yolo format\n",
    "    for index, bboxes in enumerate(converted_bboxes):\n",
    "        patch_yolo_bboxes = []\n",
    "        for bbox in bboxes:\n",
    "            if len(bbox) == 0:\n",
    "                continue\n",
    "            patch_yolo_bboxes.append(convert_standard_bbox_to_yolo_format(\n",
    "                bbox, patch_width, patch_height))\n",
    "\n",
    "        pd.DataFrame(patch_yolo_bboxes).to_csv(output_labels_folder + filename +\n",
    "                                               '_patch_' + str(index) + '.txt', sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Patches with COCO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 supported images found in the images folder\n"
     ]
    }
   ],
   "source": [
    "# @title ### Pachify Paramters { display-mode: \"form\" }\n",
    "# @markdown ### Provide the path to the dataset folder\n",
    "\n",
    "import glob\n",
    "\n",
    "def create_folder_if_not_exist(folder_path):\n",
    "  if os.path.isdir(folder_path) == False:\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "\n",
    "patch_width = 2048  # @param {type:\"integer\"}\n",
    "patch_height = 2048  # @param {type:\"integer\"}\n",
    "patch_step = 2048  # @param {type:\"integer\"}\n",
    "\n",
    "images_folder = ''  # @param {type:\"string\"}\n",
    "if os.path.isdir(images_folder) == False:\n",
    "    print('Images folder does not exist: ', images_folder)\n",
    "\n",
    "num_of_supported_images = len(glob.glob1(images_folder, '*.png'))\n",
    "if num_of_supported_images== 0:\n",
    "    print('No supported images found in the images folder')\n",
    "else:\n",
    "   print(num_of_supported_images, 'supported images found in the images folder')\n",
    "\n",
    "coco_labels_folder = '' # @param {type:\"string\"}\n",
    "coco_labels_file = os.path.join(coco_labels_folder)\n",
    "#check if coco_labels_file exists\n",
    "if os.path.isfile(coco_labels_file) == False:\n",
    "    print('Label file does not exist: ', coco_labels_file)\n",
    "\n",
    "output_images_folder = '' # @param {type:\"string\"}\n",
    "output_images_folder = os.path.join(output_images_folder)\n",
    "create_folder_if_not_exist(output_images_folder)\n",
    "\n",
    "output_labels_folder = '' # @param {type:\"string\"}\n",
    "output_labels_folder = os.path.join(output_labels_folder)\n",
    "create_folder_if_not_exist(output_labels_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import albumentations as A\n",
    "\n",
    "transform_1 = A.Compose([\n",
    "    A.Crop(x_min=0, y_min=0, x_max=2048, y_max=2048, always_apply=True),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "transform_2 = A.Compose([\n",
    "    A.Crop(x_min=2049, y_min=0, x_max=4096, y_max=2048, always_apply=True),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "transform_3 = A.Compose([\n",
    "    A.Crop(x_min=0, y_min=2049, x_max=2048, y_max=4096, always_apply=True),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "transform_4 = A.Compose([\n",
    "    A.Crop(x_min=2049, y_min=2049, x_max=4096, y_max=4096, always_apply=True),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "transform_horizontal_flip = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "# Vertical flip\n",
    "transform_vertical_flip = A.Compose([\n",
    "    A.VerticalFlip(p=1),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "# 90 degree rotation clockwise\n",
    "transform_rotate90cw = A.Compose([\n",
    "    A.Rotate(p=1, limit=[-90, -90]),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "# 180 degree rotation clockwise\n",
    "transform_rotate180cw = A.Compose([\n",
    "    A.Rotate(p=1, limit=[-180, -180]),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "# 270 degree rotation clockwise\n",
    "transform_rotate270cw = A.Compose([\n",
    "    A.Rotate(p=1, limit=[-270, -270]),\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
    "\n",
    "def transform_image(image, bboxes, category_ids, transform_function):\n",
    "    transformed = transform_function(image=image, bboxes=bboxes,\n",
    "                                     category_ids=category_ids)\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "def save_transform_image(transformed, output_annotations_data, new_image_name, output_image_folder):\n",
    "    transformed_image = transformed['image']\n",
    "    transformed_bboxes = transformed['bboxes']\n",
    "    full_image_name = f\"{new_image_name}.png\"\n",
    "\n",
    "    output_image_path = os.path.join(output_image_folder, full_image_name)\n",
    "    transformed_image = cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_image_path, transformed_image)\n",
    "\n",
    "    new_image_id = len(output_annotations_data[\"images\"])\n",
    "\n",
    "    output_annotations_data[\"images\"].append({\n",
    "        \"id\": new_image_id,\n",
    "        \"height\": transformed_image.shape[0],\n",
    "        \"width\": transformed_image.shape[1],\n",
    "        \"file_name\": full_image_name,\n",
    "    })\n",
    "\n",
    "    # Append transformed annotations\n",
    "    for bbox, category_id in zip(transformed_bboxes, transformed['category_ids']):\n",
    "        new_annotation_id = len(output_annotations_data[\"annotations\"])\n",
    "        output_annotations_data[\"annotations\"].append({\n",
    "            'id': new_annotation_id,\n",
    "            'image_id': new_image_id,\n",
    "            'category_id': 3 if is_bbox_touch_edge(bbox) and category_id != 1 else category_id,\n",
    "            'bbox': list(bbox),\n",
    "            'iscrowd': 0,\n",
    "            # assuming bbox is in format [x, y, width, height]\n",
    "            'area': bbox[2] * bbox[3]\n",
    "        })\n",
    "\n",
    "    return output_annotations_data\n",
    "\n",
    "def is_bbox_touch_edge(bbox, patch_width=2048, patch_height=2048):\n",
    "    x_min, y_min, bbox_width, bbox_height = bbox\n",
    "    x_max = x_min + bbox_width\n",
    "    y_max = y_min + bbox_height\n",
    "\n",
    "    x_axis_threshold = 5\n",
    "    y_axis_threshold = 5\n",
    "\n",
    "    if x_min <= x_axis_threshold or x_max >= patch_width - x_axis_threshold:\n",
    "        return True\n",
    "    \n",
    "    if y_min <= y_axis_threshold or y_max >= patch_height - y_axis_threshold:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def process_images(coco_labels_file, images_folder, output_image_folder, output_label_folder):\n",
    "    with open(coco_labels_file, 'r') as f:\n",
    "        annotations_data = json.load(f)\n",
    "\n",
    "    output_annotations_data = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": annotations_data[\"categories\"]\n",
    "    }\n",
    "    images_total_count = len(annotations_data['images'])\n",
    "\n",
    "    # Iterate all annoations and split them base on images\n",
    "    bboxes_by_image = {}\n",
    "    category_ids_by_image = {}\n",
    "    for ann in annotations_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in bboxes_by_image:\n",
    "            bboxes_by_image[image_id] = []\n",
    "        if image_id not in category_ids_by_image:\n",
    "            category_ids_by_image[image_id] = []\n",
    "        \n",
    "        bboxes_by_image[image_id].append(ann['bbox'])\n",
    "        category_ids_by_image[image_id].append(ann['category_id'])\n",
    "\n",
    "    for img_data in annotations_data['images']:\n",
    "        print(f\"Process image {img_data['file_name']} ({img_data['id'] + 1}/{images_total_count})\")\n",
    "        image_path = os.path.join(images_folder, img_data['file_name'])\n",
    "        image = cv2.imread(image_path)\n",
    "        image_name = img_data['file_name'].split('.')[0]\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        bboxes = bboxes_by_image[img_data['id']]\n",
    "        category_ids = category_ids_by_image[img_data['id']]\n",
    "        \n",
    "        crop_functions = [\n",
    "            transform_1,\n",
    "            transform_2,\n",
    "            transform_3,\n",
    "            transform_4\n",
    "        ]\n",
    "\n",
    "        augmentation_functions = {\n",
    "            'horizontal_flip': transform_horizontal_flip,\n",
    "            'vertical_flip': transform_vertical_flip,\n",
    "            'rotate90cw': transform_rotate90cw,\n",
    "            'rotate180cw': transform_rotate180cw,\n",
    "            'rotate270cw': transform_rotate270cw\n",
    "        }\n",
    "\n",
    "        for patch_index, augmentation_function in enumerate(crop_functions):\n",
    "            transform_result = transform_image(image, bboxes, category_ids, augmentation_function)\n",
    "            patch_file_name = f\"{image_name}_patch_{patch_index}\"\n",
    "            # output_annotations_data = save_transform_image(\n",
    "            #     transform_result, output_annotations_data, patch_file_name, output_image_folder)\n",
    "            \n",
    "            for augmentation_index, augmentation_function in augmentation_functions.items():\n",
    "                transform_result = transform_image(\n",
    "                    transform_result[\"image\"], transform_result[\"bboxes\"], transform_result['category_ids'], augmentation_functions[augmentation_index])\n",
    "                output_annotations_data = save_transform_image(\n",
    "                    transform_result, output_annotations_data, f\"{patch_file_name}_{augmentation_index}\", output_image_folder)    \n",
    "        \n",
    "    \n",
    "    print('Saving annotations file')\n",
    "    output_annotations_file = os.path.join(output_label_folder, f\"coco.json\")\n",
    "    with open(output_annotations_file, 'w') as f:\n",
    "        json.dump(output_annotations_data, f)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(coco_labels_file, images_folder, output_images_folder, output_labels_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert COCO labels to YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ### Covert COCO labels to YOLO { display-mode: \"form\" }\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def convert_coco_bbox_to_yolo_format(category_id, coco_bbox, img_width=2048, img_height=2048):\n",
    "    label = category_id\n",
    "    x_min, y_min, bbox_width, bbox_height = coco_bbox\n",
    "\n",
    "    x_center = x_min + (bbox_width / 2)\n",
    "    y_center = y_min + (bbox_height / 2)\n",
    "\n",
    "    norm_x_center = x_center / img_width\n",
    "    norm_y_center = y_center / img_height\n",
    "    norm_width = bbox_width / img_width\n",
    "    norm_height = bbox_height/ img_height\n",
    "\n",
    "    return [label, norm_x_center, norm_y_center, norm_width, norm_height]\n",
    "\n",
    "\n",
    "coco_labels_file = ''  # @param {type:\"string\"}\n",
    "coco_labels_file = os.path.join(coco_labels_file)\n",
    "#check if coco_labels_file exists\n",
    "if os.path.isfile(coco_labels_file) == False:\n",
    "    print('Label file does not exist: ', coco_labels_file)\n",
    "\n",
    "output_yolo_labels_folder = '' # @param {type:\"string\"}\n",
    "output_yolo_labels_folder = os.path.join(output_yolo_labels_folder)\n",
    "if os.path.isdir(output_yolo_labels_folder) == False:\n",
    "    os.mkdir(output_yolo_labels_folder)\n",
    "\n",
    "with open(coco_labels_file, 'r') as f:\n",
    "    annotations_data = json.load(f)\n",
    "\n",
    "images_total_count = len(annotations_data['images'])\n",
    "# Iterate all annoations and split them base on images\n",
    "bboxes_by_image = {}\n",
    "category_ids_by_image = {}\n",
    "for ann in annotations_data['annotations']:\n",
    "    image_id = ann['image_id']\n",
    "    if image_id not in bboxes_by_image:\n",
    "        bboxes_by_image[image_id] = []\n",
    "    if image_id not in category_ids_by_image:\n",
    "        category_ids_by_image[image_id] = []\n",
    "\n",
    "    bboxes_by_image[image_id].append(ann['bbox'])\n",
    "    category_ids_by_image[image_id].append(ann['category_id'])\n",
    "\n",
    "#iterate all images to generate yolo labels\n",
    "for img_data in annotations_data['images']:\n",
    "    print(f\"Process image {img_data['file_name']} ({img_data['id'] + 1}/{images_total_count})\")\n",
    "    image_name = img_data['file_name'].split('.')[0]\n",
    "    label_file = os.path.join(output_yolo_labels_folder, image_name + '.txt')\n",
    "\n",
    "    bboxes = bboxes_by_image[img_data['id']]\n",
    "    category_ids = category_ids_by_image[img_data['id']]\n",
    "\n",
    "    yolo_bboxes = []\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        yolo_bboxes.append(convert_coco_bbox_to_yolo_format(category_id, bbox, img_data['width'], img_data['height']))\n",
    "\n",
    "    pd.DataFrame(yolo_bboxes).to_csv(label_file, sep=' ', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
